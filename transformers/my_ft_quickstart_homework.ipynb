{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82901df9-c401-44ec-84f3-86a3f6195b77",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers 微调训练入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64f9f-9b2a-441c-bbe9-ddeb21a1ed0c",
   "metadata": {},
   "source": [
    "## Homework: 使用完整的 YelpReviewFull 数据集训练，看 Acc 最高能到多少"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afdf93-3ecf-4a18-8086-ebac517d605d",
   "metadata": {},
   "source": [
    "### 下载/加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00abdb68-2eef-4582-ac3e-4409e68669fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载/加载数据集\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4f758-2648-499e-9928-678664221f50",
   "metadata": {},
   "source": [
    "### 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd033e2-ed8e-421d-a0b7-4fd89cfba500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 预处理数据\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e818eec-8e87-4fc1-a98b-0f7240a1e467",
   "metadata": {},
   "source": [
    "### 拆分训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8019bf9-1316-45c3-988e-74dee864a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 585000; valid: 65000; test: 50000\n"
     ]
    }
   ],
   "source": [
    "# 设置训练(90%)/验证数据集(10%)\n",
    "# 这里我从训练集中抽出了10%作为验证集，从Chatgpt的回复看，验证集不参与训练，但是从验证集评估结果，可能会调整超参数，建议是不要和测试集重叠。\n",
    "# 但是我这边练习时并不会去根据评估结果调整超参数，如果用测试集作为验证集，训练集还能更大更全点。\n",
    "train_testvalid = tokenized_datasets['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = train_testvalid['train']\n",
    "valid_dataset = train_testvalid['test']\n",
    "test_dataset = tokenized_datasets['test']\n",
    "print(f\"train: {len(train_dataset)}; valid: {len(valid_dataset)}; test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e19d1e-8b65-4567-8441-d89bcf7f061f",
   "metadata": {},
   "source": [
    "### 设置评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51164c04-67f3-42d5-a3a9-a46465422395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置评估指标\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f77ad-e24d-49b6-b47b-a84823c25d32",
   "metadata": {},
   "source": [
    "### 加载Bert模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7583cec-a9ce-489a-a32d-2ca5b23748c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 加载Bert模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3369c-2907-40b1-93eb-01d69ff6951c",
   "metadata": {},
   "source": [
    "### 设置训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac7240f-1803-405c-b103-e633ebe70cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  eval_steps=1000,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=1000\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155bd82-e786-4d8b-bb1a-955360d044b9",
   "metadata": {},
   "source": [
    "### 实例化训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7be90382-5d89-40e5-aff6-68a70ee94c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49adb6-0238-46d9-b7eb-d93e763877cc",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bfdf9e6-5d7c-43db-8b38-9585388fb58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18162' max='109689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18162/109689 16:44:46 < 84:24:06, 0.30 it/s, Epoch 0.50/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>0.896294</td>\n",
       "      <td>0.609446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.988739</td>\n",
       "      <td>0.570277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>0.879501</td>\n",
       "      <td>0.615354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.881300</td>\n",
       "      <td>0.908441</td>\n",
       "      <td>0.620523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.876300</td>\n",
       "      <td>0.839609</td>\n",
       "      <td>0.630754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.863700</td>\n",
       "      <td>0.824819</td>\n",
       "      <td>0.638138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.645200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.846700</td>\n",
       "      <td>0.855841</td>\n",
       "      <td>0.616938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.825042</td>\n",
       "      <td>0.639031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.812349</td>\n",
       "      <td>0.652338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.812615</td>\n",
       "      <td>0.651231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.825300</td>\n",
       "      <td>0.820015</td>\n",
       "      <td>0.645938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.819100</td>\n",
       "      <td>0.792836</td>\n",
       "      <td>0.652631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.822700</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.652462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.809961</td>\n",
       "      <td>0.640831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.802670</td>\n",
       "      <td>0.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.799979</td>\n",
       "      <td>0.646538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.791550</td>\n",
       "      <td>0.655692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 开始训练\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/trainer.py:1927\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m-> 1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/trainer_callback.py:392\u001b[0m, in \u001b[0;36mCallbackHandler.on_step_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_step_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_step_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/trainer_callback.py:414\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/utils/notebook.py:305\u001b[0m, in \u001b[0;36mNotebookProgressCallback.on_step_end\u001b[0;34m(self, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_step_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    304\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(state\u001b[38;5;241m.\u001b[39mepoch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(state\u001b[38;5;241m.\u001b[39mepoch) \u001b[38;5;241m==\u001b[39m state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_next_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_next_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/utils/notebook.py:161\u001b[0m, in \u001b[0;36mNotebookProgressBar.update\u001b[0;34m(self, value, force_update, comment)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicted_remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m-\u001b[39m value)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_value \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_time \u001b[38;5;241m=\u001b[39m current_time\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/utils/notebook.py:186\u001b[0m, in \u001b[0;36mNotebookProgressBar.update_bar\u001b[0;34m(self, value, comment)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m it/s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/transformers/utils/notebook.py:229\u001b[0m, in \u001b[0;36mNotebookTrainingTracker.display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m disp\u001b[38;5;241m.\u001b[39mdisplay(disp\u001b[38;5;241m.\u001b[39mHTML(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_code), display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/IPython/core/display_functions.py:374\u001b[0m, in \u001b[0;36mDisplayHandle.update\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update existing displays with my id\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m        additional keyword arguments passed to update_display\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     \u001b[43mupdate_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/IPython/core/display_functions.py:326\u001b[0m, in \u001b[0;36mupdate_display\u001b[0;34m(obj, display_id, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update an existing display by id\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m:func:`display`\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    325\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/IPython/core/formatters.py:148\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    145\u001b[0m format_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    146\u001b[0m md_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipython_display_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# object handled itself, don't proceed\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, {}\n\u001b[1;32m    152\u001b[0m format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmimebundle_formatter(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/decorator.py:231\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m--> 231\u001b[0m         args, kw \u001b[38;5;241m=\u001b[39m \u001b[43mfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/decorator.py:203\u001b[0m, in \u001b[0;36mfix\u001b[0;34m(args, kwargs, sig)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix\u001b[39m(args, kwargs, sig):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Fix args and kwargs to be consistent with the signature\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     ba \u001b[38;5;241m=\u001b[39m \u001b[43msig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     ba\u001b[38;5;241m.\u001b[39mapply_defaults()  \u001b[38;5;66;03m# needed for test_dan_schult\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ba\u001b[38;5;241m.\u001b[39margs, ba\u001b[38;5;241m.\u001b[39mkwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.10/inspect.py:3179\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3176\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3177\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m-> 3179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_arguments_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b9152-f419-4b9f-bf08-fd5025fbdc8b",
   "metadata": {},
   "source": [
    "### 问题：验证集评估太频繁影响训练效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8b2e848-ed1b-4a1c-b3b6-715404a6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=1000\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78341b3c-164e-47b0-a2d1-7ba5259a118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b431b34c-274b-4cbf-8a10-7ffa6e2fa00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109689' max='109689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109689/109689 4:02:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.766864</td>\n",
       "      <td>0.689215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=109689, training_loss=0.04552924071479934, metrics={'train_runtime': 14528.947, 'train_samples_per_second': 120.793, 'train_steps_per_second': 7.55, 'total_flos': 4.6177234002432e+17, 'train_loss': 0.04552924071479934, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 继续训练模型\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bbf44-3e4c-4f7c-9bb0-266bb7873d22",
   "metadata": {},
   "source": [
    "### 问题: 硬盘容量不足，训练暂停\n",
    "\n",
    "硬盘从300G扩容至1T后，继续训练。\n",
    "\n",
    "**原因**：checkpoint占用太多\n",
    "虽然保存检查点可以在训练中断时提供恢复能力，但保存过于频繁会占用大量磁盘空间并降低训练速度。通过合理设置 `save_steps`、`save_total_limit` 和 `save_strategy` 参数，可以找到一个平衡点，既保证模型训练的可靠性，又不会过多地消耗资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6684fc-0220-4eaa-82a5-01a631805018",
   "metadata": {},
   "source": [
    "### 保存模型和训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7cacb15-531a-459d-8235-cdc56491be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型和训练状态\n",
    "trainer.save_model(model_dir)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f58e3-a03f-42cd-a130-9eb7798a6d7f",
   "metadata": {},
   "source": [
    "### 使用测试集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fab68a-a3e4-410c-bbd4-c87aa9a73fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 585000; valid: 65000; test: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 25:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7690914869308472,\n",
       " 'eval_accuracy': 0.68698,\n",
       " 'eval_runtime': 1501.5222,\n",
       " 'eval_samples_per_second': 33.3,\n",
       " 'eval_steps_per_second': 4.162}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 下载/加载数据集\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# # 预处理数据\n",
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # 拆分数据集\n",
    "# train_testvalid = tokenized_datasets['train'].train_test_split(test_size=0.1)\n",
    "# train_dataset = train_testvalid['train']\n",
    "# valid_dataset = train_testvalid['test']\n",
    "# test_dataset = tokenized_datasets['test']\n",
    "# print(f\"train: {len(train_dataset)}; valid: {len(valid_dataset)}; test: {len(test_dataset)}\")\n",
    "\n",
    "# # 加载模型\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "# model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# # 设置评估指标\n",
    "# import numpy as np\n",
    "# import evaluate\n",
    "\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# # 训练超参数\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# training_args = TrainingArguments(output_dir=model_dir,\n",
    "#                                   evaluation_strategy=\"epoch\",\n",
    "#                                   per_device_train_batch_size=16,\n",
    "#                                   num_train_epochs=3,\n",
    "#                                   logging_steps=500\n",
    "#                                 )\n",
    "\n",
    "# # 实例化训练器\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=valid_dataset,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f6286-65a6-4e51-aed7-ea36f2b3ab0d",
   "metadata": {},
   "source": [
    "### 通过checkpoints计算评估训练中间结果（延后）\n",
    "训练因为磁盘满中断，原代码块忘记复制后执行，导致训练前两轮评估记录丢失，尝试从state和checkpoints得到评估数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eedd259-4332-4164-9b2e-26e1f51e633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169567faea0e4a0aa9eb41ceb87aa737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating checkpoints:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8125' max='8125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8125/8125 32:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8125' max='8125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8125/8125 32:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8125' max='8125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8125/8125 32:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 检查点列表\n",
    "checkpoints = [36000, 72000, 109000]\n",
    "\n",
    "# 存储评估结果\n",
    "results = []\n",
    "\n",
    "# 评估每个检查点，使用tqdm显示进度条\n",
    "for checkpoint in tqdm(checkpoints, desc=\"Evaluating checkpoints\"):\n",
    "    checkpoint_path = f\"./models/bert-base-cased-finetune-yelp//checkpoint-{checkpoint}\"\n",
    "    # 加载特定检查点的模型\n",
    "    chp_model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "    \n",
    "    # 创建新的Trainer对象\n",
    "    chp_trainer = Trainer(\n",
    "        model=chp_model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    eval_results = chp_trainer.evaluate()\n",
    "    \n",
    "    # 提取训练损失（需要从保存的训练状态中提取）\n",
    "    train_loss = None\n",
    "    if trainer_state and hasattr(trainer_state, 'log_history'):\n",
    "        for log in trainer_state.log_history:\n",
    "            if log.get('step', None) == checkpoint and 'loss' in log:\n",
    "                train_loss = log['loss']\n",
    "                break\n",
    "    \n",
    "    # 记录结果\n",
    "    results.append({\n",
    "        'steps': checkpoint,\n",
    "        'training_loss': train_loss,\n",
    "        'validation_loss': eval_results['eval_loss'],\n",
    "        'accuracy': eval_results['eval_accuracy']\n",
    "    })\n",
    "\n",
    "# 创建DataFrame并打印结果\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 可选：将结果保存到CSV文件\n",
    "df.to_csv(\"text_classification_eval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514830cc-0f0a-4814-8433-a1d80e68f1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.713713</td>\n",
       "      <td>0.692831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.623812</td>\n",
       "      <td>0.732292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.526862</td>\n",
       "      <td>0.784892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps training_loss  validation_loss  accuracy\n",
       "0   36000          None         0.713713  0.692831\n",
       "1   72000          None         0.623812  0.732292\n",
       "2  109000          None         0.526862  0.784892"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1a579-32d7-4294-b863-06bdb820874c",
   "metadata": {},
   "source": [
    "跑上段代码时，valid_dataset划分改变了，里面混入了参与训练的样本，所以accuracy看起来变高了。\n",
    "\n",
    "应该用测试集，看看在不同checkpoint的评估结果。  \n",
    "\n",
    "traing_loss拿不到就算了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f81c06-a66e-4e59-95e9-2e7fca37692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43568a7279604e0e82ab47a4b237b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating checkpoints:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 25:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 25:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 25:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 检查点列表\n",
    "checkpoints = [36000, 72000, 109000]\n",
    "\n",
    "# 存储评估结果\n",
    "results = []\n",
    "\n",
    "# 评估每个检查点，使用tqdm显示进度条\n",
    "for checkpoint in tqdm(checkpoints, desc=\"Evaluating checkpoints\"):\n",
    "    checkpoint_path = f\"./models/bert-base-cased-finetune-yelp//checkpoint-{checkpoint}\"\n",
    "    # 加载特定检查点的模型\n",
    "    chp_model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "    \n",
    "    # 创建新的Trainer对象\n",
    "    chp_trainer = Trainer(\n",
    "        model=chp_model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    eval_results = chp_trainer.evaluate()\n",
    "    \n",
    "    # 记录结果\n",
    "    results.append({\n",
    "        'steps': checkpoint,\n",
    "        'validation_loss': eval_results['eval_loss'],\n",
    "        'accuracy': eval_results['eval_accuracy']\n",
    "    })\n",
    "\n",
    "# 创建DataFrame并打印结果\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 可选：将结果保存到CSV文件\n",
    "df.to_csv(\"text_classification_eval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab764b28-38a6-4dfa-9ab1-16cfd3d9398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>0.764091</td>\n",
       "      <td>0.66892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72000</td>\n",
       "      <td>0.731155</td>\n",
       "      <td>0.68264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109000</td>\n",
       "      <td>0.769079</td>\n",
       "      <td>0.68718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steps  validation_loss  accuracy\n",
       "0   36000         0.764091   0.66892\n",
       "1   72000         0.731155   0.68264\n",
       "2  109000         0.769079   0.68718"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948ed04-5680-4c04-8d14-b55af969bb88",
   "metadata": {},
   "source": [
    "### 更多epoch训练（延后）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816324f0-1601-4f21-900d-4e1bfd04b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载/加载数据集\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# 预处理数据\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 拆分数据集\n",
    "train_testvalid = tokenized_datasets['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = train_testvalid['train']\n",
    "valid_dataset = train_testvalid['test']\n",
    "test_dataset = tokenized_datasets['test']\n",
    "print(f\"train: {len(train_dataset)}; valid: {len(valid_dataset)}; test: {len(test_dataset)}\")\n",
    "\n",
    "# 设置评估指标\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "# 加载模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "\n",
    "# 训练超参数\n",
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=500,\n",
    "                                  save_total_limit=5\n",
    "                                )\n",
    "\n",
    "# 实例化训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f28bf7-8a72-4798-bc35-2498f7e0ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b915ac8-bd94-4e01-add4-f2385f1261f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ddfc17-54f2-4ca6-88b0-7cd323207753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型和训练状态\n",
    "trainer.save_model(model_dir)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d0d50-372d-45cc-af57-70d8356dbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
